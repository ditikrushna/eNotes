---
layout: post
title: "Discrete Optimization by The University of Melbourne"
categories: misc
author: "Ditikrushna Giri"
---

### Week 1 : 

**Practial Implementation Tip:**
 - **DFS Branch and Bound**
	- It pays off quite well to sort the inputs by either value, weight, or value/weight 
     - **Investigate:** The optimum stratergy should be to check the entropy of the field and choose the one with lowest 
  - **Dynamic Programming**
	  - It could be speeded up by using sparse tables to represent 	transition points
       - The pseudo-polynomial time concept can be understood by constructing a DP table for non-integral weight values ;)
- **Greedy Algorithms**
    - Pick one item at a time greedily with diff. heuristic.
    - Choose the smallest item first
	- Choose the most valuable item first
	- Better than the earlier methods? We can using the structure of problem
	- Value density, value per Kg ( Specific to Indiana Jones example )
	 - **Properties:**
		 - They give you a baseline
		 - No garuantee if we have an optimal situation (in general)
		 - The optimality of the solution depends upon the input
		 - In general, we can always try to solve a problem using greedy approach and then improve over it using other methods
 - **Modeling** [How to formalize an optimzation task as a mathematical model?] 
	 - 1 dimensional knapsack problem
		 - Set of items I, each item i in I
		 - its weight Wi and value Vi
		 - capacity K for a knapsack
		 - ***Objective:*** Maximize the value, with items weight less than K
	- ***First thing:*** Choose the decision variables ( they encode the result )
	- ***Second thing:*** Model the problem constraints in term of the decision variables	
	- ***Last thing:*** Specify the objective function
	- We have an optimization problem in the end. We know what we want to solve, but how is still not there
	- The way we have defined our variables is already making some restrictions on the solutions we can explore.
	- ***Analyzing Knapsack problem:***
		- X<sub>i</sub> is a decision variable. Its value is 1, if it is selected and 0 if not.
		- Constraint: Sum over i ( W<sub>i</sub>*X<sub>i</sub>) <= K
		- Objective function : Max {Sum over i (V<sub>i</sub>*X<sub>i</sub>)}
		- We have a lot of configurations (0,0,0,...0), (0,0,0,...,1), ... ,(1,1,1,...,1) : 2^<sup>N</sup>
		- Not all of them are feasible as we can not exceed the capacity of the knapsack
		- 1 milli second per problem, 50 items, 2^<sup>50</sup> evaluation will take a billion century approx.
		- Therefore, we need a smarter way to find a high quality solution.
 - **Dynamic Programming**
	- Finding the best knapsack solutions using dynamic programming
	- Used hevaily in computational biology
	- ***Basic principle:***
		- Divide and Conquer
		- Bottom up computation
	- ***Basic convention ( Bellman Equations ):***
		- Assume I = **{1,2,..n}**
		- **O(k,j)** denotes the optimal soltuion to knapsack with capacity **K** and items **[1..j]** 
		- Assum we know how to slove **O(k,j-1)**
		- We want to solve **O(k,j)** that is we want to just add one more item
		- If W<sub>j</sub> <= k
			- Either we do not select item j, the best solution we have is O(k,j-1)
			- We select the item j, best soltuion is V<sub>j</sub> + O(k-W<sub>j</sub>,j-1) 
		- O(k,j) = max(O(k,j-1), V<sub>j</sub>+O(k-W<sub>j</sub>,j-1)) if W<sub>j</sub><=k else O(k,j) = O(k,j-1)
		- Ofcourse O(k,0) = 0 for all k
	- Understand/Code the program
	- Discusses disadvantage of top-down with fibonnaci ( Where we compute some terms redundantly )
	- Dynamic programming with bottom up approach
	- Table intution for knapsack in dynamic programming ( IMPORTANT )
	- Table intutuion for Linear equation
- **Branch and Bound and Relaxation:**
	- Exhaustive search explores the entire hierarchail tree
	- In B&B we just search a part of the tree
	- ***B&B:***
		- Iterative two steps: Branching and Bounding
		- **Branching:** splits problems in subproblems ( like in exhaustive search )
		- **Bounding:** find an optimistic evaluation
			- *maximization:* upper bound
			- *minimization:* lower bound
		- How to find the optimistic estimate?
			- Relaxation
		- Nice example 5:00 for depth first branch and bound
			- Better approximation helps to prune tree earlier
		- Instead of binary assignment, we can take fraction ( Belgian chocolate )
		- This is known as linear relaxation (0 <= X<sub>i</sub> <=1)
		- In this case we can order items by V<sub>i</sub>/W<sub>i</sub>
	- Now, select the items while capactiy is not exhausted ( ***Slide 12*** )
	- Nice example to see benefit of good relaxation(**Slide 15**). Even though artifacts can not be broken but using this sort of relaxation, helps us to come up with a nice approximation for B&B.
